**同步爬虫的弊端：**

什么是同步爬虫？下面代码URL是一个个爬取的，只有等一个数据爬取完，才能爬第二个，这样效率太低了。

```
import time

def get_page(url):
    print(f'正在爬取{url}')
    time.sleep(1)
    return 0

urls = ['url1', 'url2', 'url3', 'url4']

star = time.time()
for url in urls:
    res = get_page(url)
end = time.time()

print(f'run time {end - star}')
```

```
正在爬取url1
正在爬取url2
正在爬取url3
正在爬取url4
run time 4.0070960521698
```

**异步爬虫的方式：**

- 多线程和多进程
  - 好处：可以为相关阻塞的操作单独开启线程或者进程，阻塞操作可以异步执行
  - 弊端：进程开启和关闭，可能反而会导致爬取速度变慢
- 线程池和进程池

