# Attention算法介绍

参考资料：

- [论文 Attension is all you need](https://arxiv.org/pdf/1706.03762.pdf) 
- [图解Attension](https://wmathor.com/index.php/archives/1450/) 
- [Attension 公式讲解](https://wmathor.com/index.php/archives/1432/) 
- [Reference](https://wmathor.com/index.php/archives/1432/) 

- [zhihu Reference1](https://zhuanlan.zhihu.com/p/47063917) 
- [zhihu Reference2](https://zhuanlan.zhihu.com/p/47282410) 

- [李宏毅attention视频讲解](https://www.youtube.com/watch?v=ugWDIIOHtPA) 
- [李宏毅self attention 1视频 讲解](https://www.youtube.com/watch?v=hYdO9CscNes&t=2s) 
- [李宏毅self attention 2视频 讲解](https://www.youtube.com/watch?v=gmsMY5kc-zw) 

思路：

- attention的设计初衷
- 介绍attention
- 介绍multi head attention
- 介绍self attention
- 介绍下attention机制的模型大小如何计算

